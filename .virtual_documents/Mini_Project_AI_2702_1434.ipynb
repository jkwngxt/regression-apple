


# Importing necessary libraries
import pandas as pd  # Import pandas for data manipulation and analysis
import numpy as np  # Import NumPy for numerical operations
from sklearn.model_selection import train_test_split  # Import train_test_split function
from sklearn.model_selection import GridSearchCV  # Importing the GridSearchCV module for hyperparameter tuning
import matplotlib.pyplot as plt  # Import matplotlib for data visualization
from sklearn.multioutput import RegressorChain  # Importing RegressorChain for multi-output regression
from sklearn import metrics  # Importing metrics for evaluating model performance

# Importing regressors
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C
from sklearn.linear_model import Lasso
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVR


import warnings
warnings.filterwarnings('ignore')








# Import Apple.csv (dataset)
apple = pd.read_csv('Apple.csv')
apple.head(5)


# Count the occurrences of each unique value in the 'region' column
apple['region'].value_counts()


# Filter rows where the region is 'Vietnam' and select only necessary columns
apple_vietnam = apple.loc[apple.region == 'Vietnam', 'Date' : 'type'].reset_index(drop=True)
apple_vietnam.head(5)


# Display information about the DataFrame apple_vietnam
apple_vietnam.info()


# Check null values
apple_vietnam.isna().sum()





# Convert the data in the 'Date' column to datetime format
apple_vietnam['Date'] = pd.to_datetime(apple_vietnam['Date'], format = '%d/%m/%Y')

# Set the 'Date' column as the index and sort by index
apple_vietnam = apple_vietnam.set_index('Date').sort_index()

apple_vietnam











# Function for spliting table by type and varieties
def split_table(df, app_type, app_variety) :
    return df.loc[df['type'] == app_type , app_variety].to_frame()





# Function for plotting the first column of the DataFrame against time
def visualize_data(df, app_type):
    # Extract the name of the first column (variety of apple)
    variety = df.columns[0]
    
    # Create a figure and axis for plotting
    fig, ax = plt.subplots()
    
    # Plot the data against time
    ax.plot(df[variety])
    
    # Set labels for the x and y axes
    ax.set_xlabel('Time')
    ax.set_ylabel('Amount')
    
    # Set title for the plot
    ax.set_title(f'Visualize data : {variety} ({app_type})')

    # Automatically format the x-axis date labels for better readability
    fig.autofmt_xdate()

    # Adjust layout to prevent clipping of labels
    plt.tight_layout()





# Function for preparing dataset by adding input_length x columns and output_length y columns
def window_input_output(input_length: int, output_length: int, data:pd.DataFrame) -> pd.DataFrame:
    df = data.copy()
    i = 1
    variety = data.columns[0]
    while i < input_length:
        df[f'x_{i}'] = df[variety].shift(-i)
        i = i + 1
    j= 0
    while j < output_length:
        df[f'y_{j}'] = df[variety].shift(-output_length-j)
        j = j + 1
    df = df.dropna(axis=0)
    return df.copy()





# Function for splitting the data into training and testing sets
def define_test_train(df, test_size):
    # Assuming the first column represents the variety of data
    variety = df.columns[0]
    
    # Extracting columns starting with 'x' as features and 'y' as target variables
    X_cols = [col for col in df.columns if col.startswith('x')]
    X_cols.insert(0, variety)  # Inserting variety column at the beginning
    
    y_cols = [col for col in df.columns if col.startswith('y')]
    
    # Splitting the data into training and testing sets 
    X_train = df[X_cols][:-test_size].values
    y_train = df[y_cols][:-test_size].values
    
    X_test = df[X_cols][-test_size:].values
    y_test = df[y_cols][-test_size:].values
    
    return X_train, X_test, y_train, y_test











# Create model
def best_params_LR(X_train, y_train):
    
    #  Hyperparameter Grid for Linear Regression
    param_grid = {
        'base_estimator__fit_intercept': [True, False],
        'base_estimator__positive': [True, False],
    }
    
    # Correctly create the Linear Regression model wrapped in a RegressorChain
    model = RegressorChain(LinearRegression())
    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

    # Fit the model to the training data
    grid_search.fit(X_train, y_train)
    
    # Retrieve Best Hyperparameters with correct prefix
    best_fit_intercept = grid_search.best_params_['base_estimator__fit_intercept']
    best_positive = grid_search.best_params_['base_estimator__positive']
    
    print("Best Fit Intercept:", best_fit_intercept)
    print("Best Positive:", best_positive)
     
    return best_fit_intercept, best_positive


def create_model_LR(X_train, y_train):
    
    best_fit_intercept, best_positive = best_params_LR(X_train, y_train)
    base_model = LinearRegression(fit_intercept=best_fit_intercept, positive=best_positive)

    # Wrap the base model with RegressorChain
    model = RegressorChain(base_estimator=base_model)

    
    model.fit(X_train, y_train) # Train the Model
    
    return model





# Create model
def create_model_DT(X_train, y_train):
    # Define Hyperparameter Grid
    param_grid = {
        'max_depth': [3, 5, 7, 10, 15],
        'ccp_alpha': [0.001, 0.01, 0.1, 1.0] 
    }
    
    # Perform Grid Search with Cross-Validation
    dt_regressor = DecisionTreeRegressor(random_state=42)
    grid_search = GridSearchCV(estimator=dt_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

    grid_search.fit(X_train, y_train)
    
    # Print the best parameters and best score obtained from GridSearchCV
    print('Best Parameters:', grid_search.best_params_)
    print('Best Score:', grid_search.best_score_)
    
    # Retrieve Best Hyperparameters
    best_max_depth = grid_search.best_params_['max_depth']
    best_alpha = grid_search.best_params_['ccp_alpha']
    
    # Create Decision Tree Regressor
    dt_reg = DecisionTreeRegressor(random_state=42, max_depth=best_max_depth, ccp_alpha=best_alpha )
    
    dt_reg.fit(X_train, y_train) # Train the Model
    
    return dt_reg





# Function for creating model
def create_model_SVR(X_train, y_train):
    # Define the grid of hyperparameters for SVR
    param_grid = {
        'base_estimator__kernel': ['rbf', 'sigmoid'],
        'base_estimator__C': [100, 1000, 10000, 100000],
        'base_estimator__epsilon': [3, 4, 5, 6, 7],
        'base_estimator__gamma': ['scale', 'auto'],
        'base_estimator__coef0': [0.0, 0.1, 1.0, 10.0]
    }

    # Initialize GridSearchCV with RegressorChain(SVR()) and the defined parameter grid
    grid_svr = GridSearchCV(RegressorChain(SVR()), param_grid, cv=5, scoring='neg_mean_squared_error')

    # Fit GridSearchCV to find the best combination of hyperparameters
    grid_svr.fit(X_train, y_train)

    # Print the best parameters and best score obtained from GridSearchCV
    print('Best Parameters:', grid_svr.best_params_)
    print('Best Score:', grid_svr.best_score_)

    # Get the best estimator from GridSearchCV and fit it to the training data
    best = grid_svr.best_estimator_
    
    return best





# Function for creating model
def create_model_RR(X_train, y_train):
    # Define the grid of hyperparameters for Ridge Regression
    param_grid = {
        'base_estimator__alpha': [0.1, 1.0, 10.0, 100.0],
        'base_estimator__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']
    }

    # Initialize GridSearchCV with RegressorChain(Ridge()) and the defined parameter grid
    grid_ridge = GridSearchCV(RegressorChain(Ridge(max_iter=15000 ,random_state=42)), param_grid, cv=5, scoring='neg_mean_squared_error')

    # Fit GridSearchCV to find the best combination of hyperparameters
    grid_ridge.fit(X_train, y_train)

    # Print the best parameters and best score obtained from GridSearchCV
    print('Best Parameters:', grid_ridge.best_params_)
    print('Best Score:', grid_ridge.best_score_)

    # Get the best estimator from GridSearchCV and fit it to the training data
    best = grid_ridge.best_estimator_
    
    return best






# Function for creating model
def create_model_LS(X_train, y_train):
    # Define the grid of hyperparameters for Lasso
    param_grid = {
        'alpha': [0.001, 0.01, 0.1, 1.0],
        'max_iter': [10000],
        'tol': [1e-4, 1e-3, 1e-2],
        'selection': ['cyclic', 'random'],
    }
    lasso = Lasso()
    # Initialize GridSearchCV with Lasso and the defined parameter grid
    grid_ls = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')

    # Fit GridSearchCV to find the best combination of hyperparameters
    grid_ls.fit(X_train, y_train)

    # Print the best parameters and best score obtained from GridSearchCV
    print('Best Parameters:', grid_ls.best_params_)
    print('Best Score:', grid_ls.best_score_)

    # Get the best estimator from GridSearchCV and fit it to the training data
    best = grid_ls.best_estimator_
    
    return best





# Function for creating model
def create_model_GP(X_train, y_train):
    # Define the grid of hyperparameters for GaussianProcessRegressor
    param_grid = {
    "alpha": [1e-10, 1e-5, 1e-2, 1e-1, 1, 1e1, 1e2, 1e5, 1e10],
    "kernel": [C(1.0, (1e-3, 1e3)) * RBF(length_scale) 
                   for length_scale in [0.01, 0.1, 0.5, 1.0, 2.0, 5.0]],
}

    # Initialize GridSearchCV with GaussianProcessRegressor() and the defined parameter grid
    grid_search = GridSearchCV(GaussianProcessRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')

    # Fit GridSearchCV to find the best combination of hyperparameters
    grid_search.fit(X_train, y_train)

    # Get the best hyperparameters from GridSearchCV
    best_alpha = grid_search.best_params_['alpha']
    best_kernel = grid_search.best_params_['kernel']


    # Print the best parameters and best score obtained from GridSearchCV
    print('Best Parameters:', grid_search.best_params_)
    print('Best Score:', grid_search.best_score_)

    # Get the best estimator from GridSearchCV and fit it to the training data
    best = GaussianProcessRegressor(kernel=best_kernel, alpha=best_alpha, normalize_y=True)
    best.fit(X_train, y_train)
    
    return best





# Function for creating model
def create_model_GBR(X_train, y_train):
    # Define the grid of hyperparameters
    param_grid = {
        'base_estimator__n_estimators': [100, 150, 200], 
        'base_estimator__learning_rate': [0.1, 0.01], 
        'base_estimator__max_depth': [3, 4, 5],
    }

    # Initialize GridSearchCV with RegressorChain(GradientBoostingRegressor()) and the defined parameter grid
    grid = GridSearchCV(RegressorChain(GradientBoostingRegressor(random_state=798)), param_grid, cv=3, scoring='neg_mean_squared_error')

    # Fit GridSearchCV to find the best combination of hyperparameters
    grid.fit(X_train, y_train)

    # Print the best parameters and best score obtained from GridSearchCV
    print('Best Parameters:', grid.best_params_)
    print('Best Score:', grid.best_score_)

    # Get the best estimator from GridSearchCV and fit it to the training data
    best = grid.best_estimator_
    
    return best





# Function for creating model
def create_model_RF(X_train, y_train):
    # Define the grid of hyperparameters for RF
    param_grid = {
        'max_depth': [3, 5, 7, 10, 15, 17, 19],
        'ccp_alpha': [0.001, 0.01, 0.1, 1.0],
        'max_features' : [1, 2, 3, 4],
        'n_estimators' : [1, 10, 100, 200]
    }

    # Initialize GridSearchCV with RandomForest and the defined parameter grid
    grid_rf = GridSearchCV(RandomForestRegressor(random_state = 896), param_grid, cv=5, scoring='neg_mean_squared_error')

    # Fit GridSearchCV to find the best combination of hyperparameters
    grid_rf.fit(X_train, y_train)

    # Print the best parameters and best score obtained from GridSearchCV
    print('Best Parameters:', grid_rf.best_params_)
    print('Best Score:', grid_rf.best_score_)

    # Get the best estimator from GridSearchCV and fit it to the training data
    best = grid_rf.best_estimator_
    
    return best





# Function for creating model
def create_model_EN(X_train, y_train):
    # Define the grid of hyperparameters for ElasticNet
    param_grid = {
        "base_estimator__alpha": [0.001, 0.005, 0.01, 0.1, 1.0],
        "base_estimator__l1_ratio": [0.1, 0.3, 0.5, 0.7, 0.9],
    }

    # Initialize GridSearchCV with RegressorChain(ElasticNet()) and the defined parameter grid
    grid_en = GridSearchCV(
        RegressorChain(ElasticNet()),
        param_grid,
        cv=5,
        scoring="neg_mean_absolute_error",
    )

    # Fit GridSearchCV to find the best combination of hyperparameters
    grid_en.fit(X_train, y_train)

    # Print the best parameters and best score obtained from GridSearchCV
    print("Best Parameters:", grid_en.best_params_)
    print("Best Score:", grid_en.best_score_)

    # Get the best estimator from GridSearchCV and fit it to the training data
    best = grid_en.best_estimator_
    best.fit(X_train, y_train)

    return best





# Calculate mean absolute percentage error
def mape(y_test, y_pred) :
    return round(np.mean(np.abs((y_test - y_pred) / y_test)) * 100, 2)


# Function for evaluating Mean Absolute Percentage Error (MAPE)
def mape_evaluation(X_test, y_test, y_preds, algorithm):
    # Calculate Mean Absolute Percentage Error (MAPE) for model
    mape_algo = mape(y_preds.reshape(1, -1), y_test.reshape(1, -1))
    
    # Calculate MAPE for baseline 
    mape_baseline = mape(X_test.reshape(1, -1), y_test.reshape(1, -1))
    
    # Generate the bar plot
    fig, ax = plt.subplots()
    x = ['Baseline', algorithm]
    y = [mape_baseline, mape_algo]
    ax.bar(x, y, width=0.4)
    ax.set_xlabel('Regressor models')
    ax.set_ylabel('MAPE (%)')
    
    # Add text labels above each bar to display the corresponding MAPE value
    for index, value in enumerate(y):
        plt.text(x=index, y=value + 0.05, s=str(value), ha='center')
    
    # Adjust layout for better readability
    plt.tight_layout()


# Function for evaluating Mean Absolute Percentage Error (MAPE) (all model)
def mape_evaluation_all(X_test, y_test, y_preds_LR, y_preds_DT, y_preds_SVR, 
                        y_preds_RR, y_preds_LS, y_preds_GP, y_preds_GB, y_preds_RF, y_preds_EN):

    # Calculate Mean Absolute Percentage Error (MAPE) for SVR model
    lr = mape(y_preds_LR.reshape(1, -1), y_test.reshape(1, -1))
    dt = mape(y_preds_DT.reshape(1, -1), y_test.reshape(1, -1))
    svr = mape(y_preds_SVR.reshape(1, -1), y_test.reshape(1, -1))
    rr = mape(y_preds_RR.reshape(1, -1), y_test.reshape(1, -1))
    ls = mape(y_preds_LS.reshape(1, -1), y_test.reshape(1, -1))
    gp = mape(y_preds_GP.reshape(1, -1), y_test.reshape(1, -1))
    gb = mape(y_preds_GB.reshape(1, -1), y_test.reshape(1, -1))
    rf = mape(y_preds_RF.reshape(1, -1), y_test.reshape(1, -1))
    en = mape(y_preds_EN.reshape(1, -1), y_test.reshape(1, -1))
    
    
    # Calculate MAPE for baseline 
    mape_baseline = mape(X_test.reshape(1, -1), y_test.reshape(1, -1))
    
    # Generate the bar plot
    fig, ax = plt.subplots()
    x = ['Baseline', 'Decision Tree', 'SVR', 'Linear', 
         'Ridge', 'Lasso', 'Gaussian', 'Gradient Boosting', 
         'Random Forest', 'Elastic Net']
    y = [mape_baseline, dt, svr, lr, rr, ls, gp, gb, rf, en]
    ax.bar(x, y)
    ax.set_xlabel('Regressor models')
    ax.set_ylabel('MAPE (%)')
    
    # Add text labels above each bar to display the corresponding MAPE value
    for index, value in enumerate(y):
        plt.text(x=index, y=value + 0.05, s=str(value), ha='center')

    plt.xticks(rotation=90)
    
    # Adjust layout for better readability
    plt.tight_layout()


# Function for visualizing the predictions
def visualize_predictions(X_test,y_test,y_preds, observations, algo) :
    fig, ax = plt.subplots(figsize=(16, 11))
    ax.plot(np.arange(0, observations, 1), X_test[1], 'b-', label='input')
    ax.plot(np.arange(observations, observations*2, 1), y_test[1], marker='.', color='blue', label='Actual')
    ax.plot(np.arange(observations, observations*2, 1), X_test[1], marker='o', color='red', label='Baseline')
    ax.plot(np.arange(observations, observations*2, 1), y_preds[1], marker='p', color='black', label= algo)
    ax.set_xlabel('Timesteps')
    ax.set_ylabel('Amount of Apple')
    plt.legend(loc=2)
    fig.autofmt_xdate()
    plt.tight_layout()


# Function for printing evaluation metrics
def print_evaluate(true, predicted):
    # Calculate Sum of Squared Errors (SSE)
    sse = np.sum((true - predicted)**2)
    
    # Calculate Mean Absolute Error (MAE)
    mae = metrics.mean_absolute_error(true, predicted)
    
    # Calculate Mean Squared Error (MSE)
    mse = metrics.mean_squared_error(true, predicted)
    
    # Calculate Root Mean Squared Error (RMSE)
    rmse = np.sqrt(mse)
    
    # Calculate R-squared (R2) score
    r2_square = metrics.r2_score(true, predicted)
    
    # Print evaluation metrics
    print('SSE:', sse)
    print('MAE:', mae)
    print('MSE:', mse)
    print('RMSE:', rmse)
    print('R2 Square:', r2_square)
    print('__________________________________')


# Function for evaluating model
def evaluate_model(X_test, y_test, model, observations, algorithm):
    # Predict test dataset by model
    y_preds = model.predict(X_test)
    
    # Print evaluation metrics
    print_evaluate(y_test, y_preds)
    
    # Visualize Mean Absolute Percentage Error (MAPE) for different models
    mape_evaluation(X_test, y_test, y_preds, algorithm)
    
    # Visualize predictions
    visualize_predictions(X_test, y_test, y_preds, observations, algorithm)

    return y_preds





# Function for creating and evaluating model
def create_and_evaluate_model(df, app_type, app_variety, algorithm):
    observations = 50  # Size for observations

    test_size = 2 # Size for testing set
    
    # Split table by type (app_type) and variety (app_variety)
    data = split_table(df, app_type, app_variety)

    # Visualize the data
    visualize_data(data, app_type)
    
    # Prepare the data by windowing_input_output 
    data = window_input_output(observations, observations, data)
    
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = define_test_train(data, test_size)
    
    # Create and train the model
    
    if (algorithm == 'SVR') :
        model = create_model_SVR(X_train, y_train)
        
    elif (algorithm == 'DT'):
        model = create_model_DT(X_train, y_train)
        
    elif (algorithm == 'Linear Regression'):
        model = create_model_LR(X_train, y_train)
        
    elif (algorithm == 'Ridge'):
        model = create_model_RR(X_train, y_train)
        
    elif (algorithm == 'Lasso'):
        model = create_model_LS(X_train, y_train)
        
    elif (algorithm == 'Gaussian Process'):
        model = create_model_GP(X_train, y_train)

    elif (algorithm == 'Gradient Boosting Regression'):
        model = create_model_GBR(X_train, y_train)
        
    elif (algorithm == 'RF'):
        model = create_model_RF(X_train, y_train)

    elif (algorithm == 'ElasticNet'):
        model = create_model_EN(X_train, y_train)
        
    else :
        return None, None, None, None

    
    # Evaluate the model
    y_preds = evaluate_model(X_train, X_test, y_train, y_test, model, observations, algorithm)
    
    return model, data, test_size, y_preds








model_envi_con_RF, df_envi_con, test_size_envi_con, y_preds_RF_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'RF')





model_envi_con_GBR, df_envi_con, test_size_envi_con, y_preds_GBR_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'Gradient Boosting Regression')





model_envi_con_LR, df_envi_con, test_size_envi_con, y_preds_LR_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'Linear Regression')





model_envi_con_DT, df_envi_con, test_size_envi_con, y_preds_DT_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'DT')





model_envi_con_SVR, df_envi_con, test_size_envi_con, y_preds_SVR_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'SVR')





model_envi_con_RR, df_envi_con, test_size_envi_con, y_preds_RR_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'Ridge')





model_envi_con_LS, df_envi_con, test_size_envi_con, y_preds_LS_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'Lasso')





model_envi_con_GP, df_envi_con, test_size_envi_con, y_preds_GP_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'Gaussian Process')





model_envi_con_EN, df_envi_con, test_size_envi_con, y_preds_EN_ec = create_and_evaluate_model(apple_vietnam, 'conventional', 'Envi', 'ElasticNet')





print(f'Size of Training set (Rows) : {df_envi_con.shape[0]-test_size_envi_con}')
print(f'Size of Test set (Rows)     : {test_size_envi_con}')

print('\n------- Dataframe (for creating and evaluation model) -------')
print(df_envi_con)
print()


X_train_ec, X_test_ec, y_train_ec, y_test_ec = define_test_train(df_envi_con, test_size_envi_con)


mape_evaluation_all(X_test_ec, y_test_ec, y_preds_LR_ec, y_preds_DT_ec, 
                    y_preds_SVR_ec, y_preds_RR_ec, y_preds_LS_ec, y_preds_GP_ec, 
                    y_preds_GBR_ec, y_preds_RF_ec, y_preds_EN_ec)








model_fuji_con_RF, df_fuji_con, test_size_fuji_con, y_preds_RF_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'RF')





model_fuji_con_GBR, df_fuji_con, test_size_fuji_con, y_preds_GBR_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'Gradient Boosting Regression')





model_fuji_con_LR, df_fuji_con, test_size_fuji_con, y_preds_LR_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'Linear Regression')





model_fuji_con_DT, df_fuji_con, test_size_fuji_con, y_preds_DT_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'DT')





model_fuji_con_SVR, df_fuji_con, test_size_fuji_con, y_preds_SVR_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'SVR')





model_fuji_con_RR, df_fuji_con, test_size_fuji_con, y_preds_RR_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'Ridge')





model_fuji_con_LS, df_fuji_con, test_size_fuji_con, y_preds_LS_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'Lasso')





model_fuji_con_GP, df_fuji_con, test_size_fuji_con, y_preds_GP_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'Gaussian Process')





model_fuji_con_EN, df_fuji_con, test_size_fuji_con, y_preds_EN_fc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Fuji', 'ElasticNet')





print(f'Size of Training set (Rows) : {df_fuji_con.shape[0]-test_size_fuji_con}')
print(f'Size of Test set (Rows)     : {test_size_fuji_con}')

print('\n------- Dataframe (for creating and evaluation model) -------')
print(df_fuji_con)
print()


X_train_fc, X_test_fc, y_train_fc, y_test_fc = define_test_train(df_fuji_con, test_size_fuji_con)


mape_evaluation_all(X_test_fc, y_test_fc, y_preds_LR_fc, y_preds_DT_fc, 
                    y_preds_SVR_fc, y_preds_RR_fc, y_preds_LS_fc, y_preds_GP_fc, 
                    y_preds_GBR_fc, y_preds_RF_fc, y_preds_EN_fc)








model_gala_con_RF, df_gala_con, test_size_gala_con, y_preds_RF_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'RF')





model_gala_con_GBR, df_gala_con, test_size_gala_con, y_preds_GBR_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'Gradient Boosting Regression')





model_gala_con_LR, df_gala_con, test_size_gala_con, y_preds_LR_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'Linear Regression')





model_gala_con_DT, df_gala_con, test_size_gala_con, y_preds_DT_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'DT')





model_gala_con_SVR, df_gala_con, test_size_gala_con, y_preds_SVR_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'SVR')





model_gala_con_RR, df_gala_con, test_size_gala_con, y_preds_RR_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'Ridge')





model_gala_con_LS, df_gala_con, test_size_gala_con, y_preds_LS_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'Lasso')





model_gala_con_GP, df_gala_con, test_size_gala_con, y_preds_GP_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'Gaussian Process')





model_gala_con_EN, df_gala_con, test_size_gala_con, y_preds_EN_gc = create_and_evaluate_model(apple_vietnam, 'conventional', 'Gala', 'ElasticNet')





print(f'Size of Training set (Rows) : {df_gala_con.shape[0]-test_size_gala_con}')
print(f'Size of Test set (Rows)     : {test_size_gala_con}')

print('\n------- Dataframe (for creating and evaluation model) -------')
print(df_gala_con)
print()


X_train_gc, X_test_gc, y_train_gc, y_test_gc = define_test_train(df_gala_con, test_size_gala_con)


mape_evaluation_all(X_test_gc, y_test_gc, y_preds_LR_gc, y_preds_DT_gc, 
                    y_preds_SVR_gc, y_preds_RR_gc, y_preds_LS_gc, y_preds_GP_gc, 
                    y_preds_GBR_gc, y_preds_RF_gc, y_preds_EN_gc)








model_envi_org_RF, df_envi_org, test_size_envi_org, y_preds_RF_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'RF')





model_envi_org_GBR, df_envi_org, test_size_envi_org, y_preds_GBR_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'Gradient Boosting Regression')





model_envi_org_LR, df_envi_org, test_size_envi_org, y_preds_LR_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'Linear Regression')





model_envi_org_DT, df_envi_org, test_size_envi_org, y_preds_DT_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'DT')





model_envi_org_SVR, df_envi_org, test_size_envi_org, y_preds_SVR_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'SVR')





model_envi_org_RR, df_envi_org, test_size_envi_org, y_preds_RR_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'Ridge')





model_envi_org_LS, df_envi_org, test_size_envi_org, y_preds_LS_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'Lasso')





model_envi_org_GP, df_envi_org, test_size_envi_org, y_preds_GP_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'Gaussian Process')





model_envi_org_EN, df_envi_org, test_size_envi_org, y_preds_EN_eo = create_and_evaluate_model(apple_vietnam, 'organic', 'Envi', 'ElasticNet')





print(f'Size of Training set (Rows) : {df_envi_org.shape[0]-test_size_envi_org}')
print(f'Size of Test set (Rows)     : {test_size_envi_org}')

print('\n------- Dataframe (for creating and evaluation model) -------')
print(df_envi_org)
print()


X_train_eo, X_test_eo, y_train_eo, y_test_eo = define_test_train(df_envi_org, test_size_envi_org)


mape_evaluation_all(X_test_eo, y_test_eo, y_preds_LR_eo, y_preds_DT_eo, 
                    y_preds_SVR_eo, y_preds_RR_eo, y_preds_LS_eo, y_preds_GP_eo, 
                    y_preds_GBR_eo, y_preds_RF_eo, y_preds_EN_eo)








model_fuji_org_RF, df_fuji_org, test_size_fuji_org, y_preds_RF_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'RF')





model_fuji_org_GBR, df_fuji_org, test_size_fuji_org, y_preds_GBR_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'Gradient Boosting Regression')





model_fuji_org_LR, df_fuji_org, test_size_fuji_org, y_preds_LR_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'Linear Regression')





model_fuji_org_DT, df_fuji_org, test_size_fuji_org, y_preds_DT_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'DT')





model_fuji_org_SVR, df_fuji_org, test_size_fuji_org, y_preds_SVR_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'SVR')





model_fuji_org_RR, df_fuji_org, test_size_fuji_org, y_preds_RR_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'Ridge')





model_fuji_org_LS, df_fuji_org, test_size_fuji_org, y_preds_LS_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'Lasso')





model_fuji_org_GP, df_fuji_org, test_size_fuji_org, y_preds_GP_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'Gaussian Process')





model_fuji_org_EN, df_fuji_org, test_size_fuji_org, y_preds_EN_fo = create_and_evaluate_model(apple_vietnam, 'organic', 'Fuji', 'ElasticNet')





print(f'Size of Training set (Rows) : {df_fuji_org.shape[0]-test_size_fuji_org}')
print(f'Size of Test set (Rows)     : {test_size_fuji_org}')

print('\n------- Dataframe (for creating and evaluation model) -------')
print(df_fuji_org)
print()


X_train_fo, X_test_fo, y_train_fo, y_test_fo = define_test_train(df_fuji_org, test_size_fuji_org)


mape_evaluation_all(X_test_fo, y_test_fo, y_preds_LR_fo, y_preds_DT_fo, 
                    y_preds_SVR_fo, y_preds_RR_fo, y_preds_LS_fo, y_preds_GP_fo, 
                    y_preds_GBR_fo, y_preds_RF_fo, y_preds_EN_fo)








model_gala_org_RF, df_gala_org, test_size_gala_org, y_preds_RF_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'RF')





model_gala_org_GBR, df_gala_org, test_size_gala_org, y_preds_GBR_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'Gradient Boosting Regression')





model_gala_org_LR, df_gala_org, test_size_gala_org, y_preds_LR_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'Linear Regression')





model_gala_org_DT, df_gala_org, test_size_gala_org, y_preds_DT_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'DT')





model_gala_org_SVR, df_gala_org, test_size_gala_org, y_preds_SVR_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'SVR')





model_gala_org_RR, df_gala_org, test_size_gala_org, y_preds_RR_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'Ridge')





model_gala_org_LS, df_gala_org, test_size_gala_org, y_preds_LS_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'Lasso')





model_gala_org_GP, df_gala_org, test_size_gala_org, y_preds_GP_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'Gaussian Process')





model_gala_org_EN, df_gala_org, test_size_gala_org, y_preds_EN_go = create_and_evaluate_model(apple_vietnam, 'organic', 'Gala', 'ElasticNet')





print(f'Size of Training set (Rows) : {df_gala_org.shape[0]-test_size_gala_org}')
print(f'Size of Test set (Rows)     : {test_size_gala_org}')

print('\n------- Dataframe (for creating and evaluation model) -------')
print(df_gala_org)
print()


X_train_go, X_test_go, y_train_go, y_test_go = define_test_train(df_gala_org, test_size_gala_org)


mape_evaluation_all(X_test_go, y_test_go, y_preds_LR_go, y_preds_DT_go, 
                    y_preds_SVR_go, y_preds_RR_go, y_preds_LS_go, y_preds_GP_go, 
                    y_preds_GBR_go, y_preds_RF_go, y_preds_EN_go)








mape_evaluation_all(X_test_ec, y_test_ec, y_preds_LR_ec, y_preds_DT_ec, 
                    y_preds_SVR_ec, y_preds_RR_ec, y_preds_LS_ec, y_preds_GP_ec, 
                    y_preds_GBR_ec, y_preds_RF_ec, y_preds_EN_ec)





mape_evaluation_all(X_test_fc, y_test_fc, y_preds_LR_fc, y_preds_DT_fc, 
                    y_preds_SVR_fc, y_preds_RR_fc, y_preds_LS_fc, y_preds_GP_fc, 
                    y_preds_GBR_fc, y_preds_RF_fc, y_preds_EN_fc)





mape_evaluation_all(X_test_gc, y_test_gc, y_preds_LR_gc, y_preds_DT_gc, 
                    y_preds_SVR_gc, y_preds_RR_gc, y_preds_LS_gc, y_preds_GP_gc, 
                    y_preds_GBR_gc, y_preds_RF_gc, y_preds_EN_gc)





mape_evaluation_all(X_test_eo, y_test_eo, y_preds_LR_eo, y_preds_DT_eo, 
                    y_preds_SVR_eo, y_preds_RR_eo, y_preds_LS_eo, y_preds_GP_eo, 
                    y_preds_GBR_eo, y_preds_RF_eo, y_preds_EN_eo)





mape_evaluation_all(X_test_fo, y_test_fo, y_preds_LR_fo, y_preds_DT_fo, 
                    y_preds_SVR_fo, y_preds_RR_fo, y_preds_LS_fo, y_preds_GP_fo, 
                    y_preds_GBR_fo, y_preds_RF_fo, y_preds_EN_fo)





mape_evaluation_all(X_test_go, y_test_go, y_preds_LR_go, y_preds_DT_go, 
                    y_preds_SVR_go, y_preds_RR_go, y_preds_LS_go, y_preds_GP_go, 
                    y_preds_GBR_go, y_preds_RF_go, y_preds_EN_go)
